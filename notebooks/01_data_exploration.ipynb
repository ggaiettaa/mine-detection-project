{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49392070-c2ec-4548-aa98-6893e07b3021",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "MINE DETECTION AND CLASSIFICATION - COMPLETE ANALYSIS\n",
        "=====================================================\n",
        "\n",
        "This notebook demonstrates:\n",
        "1. Data Loading and Exploration\n",
        "2. Data Preprocessing\n",
        "3. Classification (Random Forest + Neural Networks)\n",
        "4. Clustering Analysis\n",
        "5. Results Comparison\n",
        "\n",
        "Authors: [Gaia Luna Acosta, Bujar Cysa]\n",
        "Date: [01/12/2025]\n",
        "\"\"\"\n",
        "\n",
        "# %% [markdown]\n",
        "# # 1. Setup and Imports\n",
        "\n",
        "# %%\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Import custom modules\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "\n",
        "from data_loader import MineDataLoader\n",
        "from preprocessing import MineDataPreprocessor\n",
        "from classification import RandomForestOptimizer\n",
        "from neural_network import NeuralNetworkExperiment\n",
        "from clustering import ClusteringAnalysis\n",
        "\n",
        "print(\"✓ All imports successful!\")\n",
        "\n",
        "# %% [markdown]\n",
        "# # 2. Load and Explore Data\n",
        "\n",
        "# %%\n",
        "# Load data\n",
        "loader = MineDataLoader('../data/processed/mine_data_clean.csv')\n",
        "df = loader.load_data(file_format='csv')\n",
        "\n",
        "# Print summary\n",
        "loader.print_summary()\n",
        "\n",
        "# Display first rows\n",
        "print(\"\\nFirst 5 samples:\")\n",
        "print(df.head())\n",
        "\n",
        "# %%\n",
        "# Visualize data distribution\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Voltage distribution by mine type\n",
        "df.boxplot(column='V', by='M', ax=axes[0, 0])\n",
        "axes[0, 0].set_title('Voltage Distribution by Mine Type')\n",
        "axes[0, 0].set_xlabel('Mine Type')\n",
        "axes[0, 0].set_ylabel('Voltage (V)')\n",
        "\n",
        "# Height distribution\n",
        "df['H'].hist(bins=30, ax=axes[0, 1], edgecolor='black')\n",
        "axes[0, 1].set_title('Height Distribution')\n",
        "axes[0, 1].set_xlabel('Height (cm)')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "\n",
        "# Soil type distribution\n",
        "df['S'].value_counts().plot(kind='bar', ax=axes[1, 0], edgecolor='black')\n",
        "axes[1, 0].set_title('Soil Type Distribution')\n",
        "axes[1, 0].set_xlabel('Soil Type')\n",
        "axes[1, 0].set_ylabel('Count')\n",
        "\n",
        "# Mine type distribution\n",
        "df['M'].value_counts().sort_index().plot(kind='bar', ax=axes[1, 1], \n",
        "                                          color=['red', 'blue', 'green', 'orange', 'purple'],\n",
        "                                          edgecolor='black')\n",
        "axes[1, 1].set_title('Mine Type Distribution')\n",
        "axes[1, 1].set_xlabel('Mine Type')\n",
        "axes[1, 1].set_ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/figures/data_exploration.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# %%\n",
        "# Correlation analysis\n",
        "X, y = loader.get_features_target()\n",
        "correlation = X.corr()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0, \n",
        "            square=True, linewidths=1)\n",
        "plt.title('Feature Correlation Matrix')\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/figures/correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# %% [markdown]\n",
        "# # 3. Data Preprocessing\n",
        "\n",
        "# %%\n",
        "preprocessor = MineDataPreprocessor()\n",
        "\n",
        "# Get features and target\n",
        "X, y = loader.get_features_target()\n",
        "\n",
        "# Check class balance\n",
        "balance = preprocessor.check_class_balance(y)\n",
        "print(\"\\nClass Balance:\")\n",
        "print(balance)\n",
        "\n",
        "# Prepare data for Random Forest\n",
        "X_rf, y_rf = preprocessor.prepare_for_random_forest(X, y)\n",
        "\n",
        "# Prepare data for Neural Network\n",
        "X_nn, y_nn = preprocessor.prepare_for_neural_network(X, y)\n",
        "\n",
        "print(f\"\\n✓ Data prepared for both Random Forest and Neural Network\")\n",
        "print(f\"Random Forest input shape: {X_rf.shape}\")\n",
        "print(f\"Neural Network input shape: {X_nn.shape}\")\n",
        "\n",
        "# %% [markdown]\n",
        "# # 4. Classification - Random Forest\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 4.1 Baseline Random Forest\n",
        "\n",
        "# %%\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data for Random Forest\n",
        "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(\n",
        "    X_rf, y_rf, test_size=0.2, random_state=42, stratify=y_rf\n",
        ")\n",
        "\n",
        "# Initialize optimizer\n",
        "rf_optimizer = RandomForestOptimizer(random_state=42)\n",
        "\n",
        "# Train baseline\n",
        "rf_baseline = rf_optimizer.train_baseline(X_train_rf, y_train_rf)\n",
        "\n",
        "# Evaluate baseline\n",
        "baseline_metrics = rf_optimizer.evaluate_model(\n",
        "    rf_baseline, X_test_rf, y_test_rf, \"Baseline Random Forest\"\n",
        ")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 4.2 Hyperparameter Tuning\n",
        "\n",
        "# %%\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 15, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Perform grid search (this may take a few minutes)\n",
        "print(\"Starting hyperparameter tuning...\")\n",
        "grid_search = rf_optimizer.grid_search_tuning(\n",
        "    X_train_rf, y_train_rf, \n",
        "    param_grid=param_grid, \n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# Evaluate optimized model\n",
        "optimized_metrics = rf_optimizer.evaluate_model(\n",
        "    rf_optimizer.optimized_model, X_test_rf, y_test_rf, \n",
        "    \"Optimized Random Forest\"\n",
        ")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 4.3 Compare Baseline vs Optimized\n",
        "\n",
        "# %%\n",
        "# Compare models\n",
        "comparison_rf = rf_optimizer.compare_models(X_test_rf, y_test_rf)\n",
        "\n",
        "# Plot comparison\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "comparison_rf.set_index('Model')[['Accuracy', 'Precision', 'Recall', 'F1-Score']].plot(\n",
        "    kind='bar', ax=ax, width=0.8\n",
        ")\n",
        "plt.title('Baseline vs Optimized Random Forest')\n",
        "plt.ylabel('Score')\n",
        "plt.ylim([0.7, 1.0])\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/figures/rf_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 4.4 Feature Importance\n",
        "\n",
        "# %%\n",
        "# Get feature importance\n",
        "importance_df = rf_optimizer.get_feature_importance(\n",
        "    feature_names=['Voltage', 'Height', 'Soil Type'],\n",
        "    model_type='optimized'\n",
        ")\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "print(importance_df)\n",
        "\n",
        "# Plot feature importance\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "importance_df.plot(x='Feature', y='Importance', kind='barh', ax=ax, legend=False)\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Feature Importance - Optimized Random Forest')\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/figures/feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 4.5 Learning Curves\n",
        "\n",
        "# %%\n",
        "# Plot learning curve\n",
        "fig = rf_optimizer.plot_learning_curve(X_rf, y_rf, model_type='optimized', cv=5)\n",
        "plt.savefig('../results/figures/learning_curve_rf.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# %% [markdown]\n",
        "# # 5. Neural Networks\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 5.1 Prepare Data\n",
        "\n",
        "# %%\n",
        "# Split data for Neural Network (train/val/test)\n",
        "X_train_nn, X_val_nn, X_test_nn, y_train_nn, y_val_nn, y_test_nn = \\\n",
        "    preprocessor.create_train_val_test_split(X_nn, y_nn)\n",
        "\n",
        "print(f\"Training set:   {X_train_nn.shape[0]} samples\")\n",
        "print(f\"Validation set: {X_val_nn.shape[0]} samples\")\n",
        "print(f\"Test set:       {X_test_nn.shape[0]} samples\")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 5.2 Create and Train Different Architectures\n",
        "\n",
        "# %%\n",
        "# Initialize experiment\n",
        "nn_exp = NeuralNetworkExperiment(\n",
        "    input_dim=X_train_nn.shape[1],\n",
        "    num_classes=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# %% [markdown]\n",
        "# ### Simple Model (2 layers)\n",
        "\n",
        "# %%\n",
        "# Create simple model\n",
        "simple_model = nn_exp.create_simple_model(learning_rate=0.001, name='simple')\n",
        "print(\"\\nSimple Model Architecture:\")\n",
        "simple_model.summary()\n",
        "\n",
        "# Train\n",
        "history_simple = nn_exp.train_model(\n",
        "    simple_model,\n",
        "    X_train_nn, y_train_nn,\n",
        "    X_val_nn, y_val_nn,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# %% [markdown]\n",
        "# ### Medium Model (3 layers with Dropout)\n",
        "\n",
        "# %%\n",
        "# Create medium model\n",
        "medium_model = nn_exp.create_medium_model(\n",
        "    learning_rate=0.001, \n",
        "    dropout_rate=0.3, \n",
        "    name='medium'\n",
        ")\n",
        "print(\"\\nMedium Model Architecture:\")\n",
        "medium_model.summary()\n",
        "\n",
        "# Train\n",
        "history_medium = nn_exp.train_model(\n",
        "    medium_model,\n",
        "    X_train_nn, y_train_nn,\n",
        "    X_val_nn, y_val_nn,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# %% [markdown]\n",
        "# ### Deep Model (4 layers with Batch Normalization)\n",
        "\n",
        "# %%\n",
        "# Create deep model\n",
        "deep_model = nn_exp.create_deep_model(\n",
        "    learning_rate=0.001,\n",
        "    dropout_rate=0.3,\n",
        "    use_batch_norm=True,\n",
        "    name='deep'\n",
        ")\n",
        "print(\"\\nDeep Model Architecture:\")\n",
        "deep_model.summary()\n",
        "\n",
        "# Train\n",
        "history_deep = nn_exp.train_model(\n",
        "    deep_model,\n",
        "    X_train_nn, y_train_nn,\n",
        "    X_val_nn, y_val_nn,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 5.3 Compare Neural Network Architectures\n",
        "\n",
        "# %%\n",
        "# Plot training histories\n",
        "fig = nn_exp.plot_training_history(figsize=(15, 5))\n",
        "plt.savefig('../results/figures/nn_training_history.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Compare all models\n",
        "comparison_nn = nn_exp.compare_all_models(X_test_nn, y_test_nn)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 5.4 Confusion Matrices\n",
        "\n",
        "# %%\n",
        "# Plot confusion matrices\n",
        "fig = nn_exp.plot_confusion_matrices(X_test_nn, y_test_nn)\n",
        "plt.savefig('../results/figures/nn_confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# %% [markdown]\n",
        "# # 6. Clustering Analysis\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 6.1 Find Optimal Number of Clusters\n",
        "\n",
        "# %%\n",
        "# Initialize clustering\n",
        "clustering = ClusteringAnalysis(random_state=42)\n",
        "\n",
        "# Find optimal K\n",
        "fig, optimal_k_results = clustering.find_optimal_k(X_nn, k_range=range(2, 11))\n",
        "plt.savefig('../results/figures/optimal_k_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 6.2 K-Means Clustering\n",
        "\n",
        "# %%\n",
        "# Perform K-Means with optimal k (5, matching number of classes)\n",
        "kmeans_model = clustering.perform_kmeans(X_nn, n_clusters=5)\n",
        "\n",
        "# Visualize clusters\n",
        "fig = clustering.visualize_clusters_2d(X_nn, 'kmeans')\n",
        "plt.savefig('../results/figures/kmeans_clusters.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Compare with true labels\n",
        "ari_kmeans = clustering.compare_with_true_labels(y_nn, 'kmeans')\n",
        "\n",
        "# Plot cluster vs true label distribution\n",
        "fig = clustering.plot_cluster_distributions(y, 'kmeans')\n",
        "plt.savefig('../results/figures/kmeans_true_labels.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 6.3 DBSCAN Clustering\n",
        "\n",
        "# %%\n",
        "# Perform DBSCAN\n",
        "dbscan_model = clustering.perform_dbscan(X_nn, eps=0.5, min_samples=5)\n",
        "\n",
        "# Visualize\n",
        "fig = clustering.visualize_clusters_2d(X_nn, 'dbscan')\n",
        "plt.savefig('../results/figures/dbscan_clusters.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 6.4 Hierarchical Clustering\n",
        "\n",
        "# %%\n",
        "# Perform hierarchical clustering\n",
        "hierarchical_model = clustering.perform_hierarchical(X_nn, n_clusters=5)\n",
        "\n",
        "# Visualize\n",
        "fig = clustering.visualize_clusters_2d(X_nn, 'hierarchical')\n",
        "plt.savefig('../results/figures/hierarchical_clusters.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Plot dendrogram\n",
        "fig = clustering.plot_dendrogram(X_nn[:100])  # Using subset for clarity\n",
        "plt.savefig('../results/figures/dendrogram.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 6.5 Compare Clustering Algorithms\n",
        "\n",
        "# %%\n",
        "comparison_clustering = clustering.compare_all_algorithms()\n",
        "\n",
        "# %% [markdown]\n",
        "# # 7. Final Comparison: All Methods\n",
        "\n",
        "# %%\n",
        "# Create comprehensive comparison\n",
        "final_results = pd.DataFrame({\n",
        "    'Method': [\n",
        "        'Random Forest (Baseline)',\n",
        "        'Random Forest (Optimized)',\n",
        "        'Neural Network (Simple)',\n",
        "        'Neural Network (Medium)',\n",
        "        'Neural Network (Deep)',\n",
        "        'K-Means (Clustering)',\n",
        "    ],\n",
        "    'Accuracy/Performance': [\n",
        "        baseline_metrics['accuracy'],\n",
        "        optimized_metrics['accuracy'],\n",
        "        comparison_nn[comparison_nn['Model'] == 'simple']['Test Accuracy'].values[0],\n",
        "        comparison_nn[comparison_nn['Model'] == 'medium']['Test Accuracy'].values[0],\n",
        "        comparison_nn[comparison_nn['Model'] == 'deep']['Test Accuracy'].values[0],\n",
        "        clustering.metrics['kmeans']['silhouette_score']\n",
        "    ],\n",
        "    'Type': ['Classification', 'Classification', 'Classification', \n",
        "             'Classification', 'Classification', 'Clustering']\n",
        "})\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL RESULTS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(final_results.to_string(index=False))\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Visualize\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "colors = ['#FF6B6B' if t == 'Classification' else '#4ECDC4' \n",
        "          for t in final_results['Type']]\n",
        "bars = ax.barh(final_results['Method'], final_results['Accuracy/Performance'], \n",
        "               color=colors, edgecolor='black', linewidth=1.5)\n",
        "ax.set_xlabel('Score')\n",
        "ax.set_title('Final Performance Comparison - All Methods')\n",
        "ax.set_xlim([0, 1])\n",
        "ax.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Add value labels\n",
        "for i, (bar, value) in enumerate(zip(bars, final_results['Accuracy/Performance'])):\n",
        "    ax.text(value + 0.01, bar.get_y() + bar.get_height()/2, \n",
        "            f'{value:.4f}', va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../results/figures/final_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# %% [markdown]\n",
        "# # 8. Save Models\n",
        "\n",
        "# %%\n",
        "# Save Random Forest models\n",
        "rf_optimizer.save_model('../results/models/rf_optimized.pkl', 'optimized')\n",
        "rf_optimizer.save_model('../results/models/rf_baseline.pkl', 'baseline')\n",
        "\n",
        "# Save best Neural Network\n",
        "nn_exp.save_model('deep', '../results/models/nn_deep.h5')\n",
        "\n",
        "print(\"✓ All models saved successfully!\")\n",
        "\n",
        "# %% [markdown]\n",
        "# # 9. Conclusions\n",
        "# \n",
        "# ## Key Findings:\n",
        "# \n",
        "# 1. **Random Forest Performance:**\n",
        "#    - Baseline accuracy: XX%\n",
        "#    - Optimized accuracy: XX%\n",
        "#    - Improvement: +XX%\n",
        "#    - Most important feature: [Feature name]\n",
        "# \n",
        "# 2. **Neural Network Performance:**\n",
        "#    - Best architecture: [Simple/Medium/Deep]\n",
        "#    - Test accuracy: XX%\n",
        "#    - Early stopping prevented overfitting\n",
        "# \n",
        "# 3. **Clustering Analysis:**\n",
        "#    - K-Means with K=5 showed best silhouette score\n",
        "#    - Clusters align moderately with true mine types (ARI: XX)\n",
        "#    - DBSCAN identified XX noise points\n",
        "# \n",
        "# 4. **Overall Best Model:** [Model name] with XX% accuracy\n",
        "# \n",
        "# ## Recommendations:\n",
        "# - [Add your recommendations based on results]\n",
        "# - [Future work suggestions]\n",
        "\n",
        "print(\"\\n✅ ANALYSIS COMPLETE!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.13 (XPython)",
      "language": "python",
      "name": "xpython"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
